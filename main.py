from data_loader import load_data, save_data
from text_cleaner import clean_text
from translator import translate_to_chinese
import time
from random import sample


def main():
    start_time = time.time()  # è¨˜éŒ„é–‹å§‹æ™‚é–“

    df = load_data("C:/Users/user/Downloads/train.csv")
    # df =  load_data("C:/Users/user/Downloads/train.csv").sample(500)
    df['clean_text'] = df['comment_text'].map(clean_text)

    print("é–‹å§‹ç¿»è­¯...")
    df['translated_text'] = translate_to_chinese(df['clean_text'].tolist())

    save_data(df, "C:/Users/user/PycharmProjects/PythonProject1/translated.csv")

    end_time = time.time()  # è¨˜éŒ„çµæŸæ™‚é–“
    elapsed_time = end_time - start_time
    print(f"è™•ç†å®Œæˆï¼Œç¸½å…±è€—æ™‚ï¼š{elapsed_time:.2f} ç§’")

if __name__ == "__main__":
    main()

#
#
# import os
# import json
# import time
# import torch
# from transformers import BertTokenizer
# from bert_model.dataset import prepare_dataloader_from_csv
# from bert_model.model import BERTClassifier
# from bert_model.train import train_model
#
# # ä¸»ç¨‹å¼å…¥å£
# def main():
#     start_time = time.time()  # è¨˜éŒ„é–‹å§‹æ™‚é–“
#
#     # df = load_data("C:/Users/user/Downloads/train.csv")
#     df =  load_data("C:/Users/user/Downloads/train.csv").sample(200)
#     df['clean_text'] = df['comment_text'].map(clean_text)
#
#     # ç¿»è­¯è³‡æ–™
#     df['translated_text'] = translate_to_chinese(df['clean_text'].tolist())
#
#     # å„²å­˜ç¿»è­¯å¾Œè³‡æ–™
#     translated_path = "C:/Users/user/PycharmProjects/PythonProject1/translated.csv"
#     df.to_csv(translated_path, index=False)
#
#     # è¨“ç·´æ¨¡å‹
#     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#     model = BERTClassifier(model_name='bert-base-chinese', num_labels=6).to(device)
#     optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
#
#     text_column = "translated_text"
#     label_columns = ["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]
#
#     train_loader, val_loader = prepare_dataloader_from_csv(
#         df = df,
#         text_column=text_column,
#         label_columns=label_columns,
#         tokenizer_name='bert-base-chinese',
#         batch_size=16,
#         max_length=128,
#         val_size=0.2
#     )
#
#     train_model(model, train_loader, val_loader, optimizer, device, num_epochs=10)
#
#     # å„²å­˜æ¨¡å‹èˆ‡ tokenizer
#     os.makedirs("bert_model/Saved_model", exist_ok=True)
#     torch.save(model.state_dict(), "bert_model/Saved_model/pytorch_model.bin")
#
#     tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
#     tokenizer.save_pretrained("bert_model/Saved_model")
#
#     config = {
#         "model_type": "bert",
#         "num_labels": 6
#     }
#     with open("bert_model/Saved_model/config.json", "w", encoding="utf-8") as f:
#         json.dump(config, f, ensure_ascii=False, indent=2)
#
#     print(f"\nğŸ å…¨éƒ¨æµç¨‹å®Œæˆï¼Œè€—æ™‚ï¼š{time.time() - start_time:.2f} ç§’")
#
# # -------------------------------
# if __name__ == "__main__":
#     main()